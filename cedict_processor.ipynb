{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas\n",
    "import sqlite3\n",
    "processed_cedict = []\n",
    "with open('cedict_1_0_ts_utf-8_mdbg.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # space, space, bracket, slash\n",
    "        pinyin = line.split('[', 1)[1].split(']', 1)[0]\n",
    "        assert all(\n",
    "            c in '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZüÜ:,· ' for c in pinyin)\n",
    "        english = line.split('/', 1)[1]\n",
    "        trad, simp = line.split(' ', 2)[:2]\n",
    "        pinyin = pinyin.replace('u:', 'ü')\n",
    "        pinyin = pinyin.replace('U:', 'Ü')\n",
    "        english = english.strip('/')\n",
    "        # english = english.replace('/', ' * ')\n",
    "        processed_cedict.append((trad, simp, pinyin, english))\n",
    "# pprint.pprint(processed_cedict)\n",
    "df = pandas.DataFrame(processed_cedict, columns=[\n",
    "                      'Traditional', 'Simplified', 'Pinyin', 'English'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chinese(word):\n",
    "    return all(u'\\u4e00' <= char <= u'\\u9fff' for char in word)\n",
    "\n",
    "\n",
    "def is_english(word):\n",
    "    return all(u'\\u0041' <= char <= u'\\u005a' or u'\\u0061' <= char <= u'\\u007a' for char in word)\n",
    "\n",
    "\n",
    "def has_punctuation(word):\n",
    "    return any(char in '.,?!:;-/' for char in word)\n",
    "\n",
    "\n",
    "def any_chinese(word):\n",
    "    return any(u'\\u4e00' <= char <= u'\\u9fff' for char in word)\n",
    "\n",
    "\n",
    "non_chinese_trad = df[~df['Traditional'].apply(is_chinese)]\n",
    "non_chinese_simp = df[~df['Simplified'].apply(is_chinese)]\n",
    "non_english = df[~df['English'].apply(is_english)]\n",
    "pinyin_chinese = df[df['Pinyin'].apply(any_chinese)]\n",
    "\n",
    "only_english_punctuation = df[~df['Traditional'].apply(has_punctuation) & ~df['Simplified'].apply(\n",
    "    has_punctuation) & ~df['Pinyin'].apply(has_punctuation)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 121606\n",
      "Non-Chinese Traditional: 1068\n",
      "Non-Chinese Simplified: 1271\n",
      "Non-English: 111848\n",
      "Pinyin Chinese: 0\n",
      "Only English Punctuation: 121143\n"
     ]
    }
   ],
   "source": [
    "print('Total:', len(df))\n",
    "print('Non-Chinese Traditional:', len(non_chinese_trad))\n",
    "print('Non-Chinese Simplified:', len(non_chinese_simp))\n",
    "print('Non-English:', len(non_english))\n",
    "print('Pinyin Chinese:', len(pinyin_chinese))\n",
    "print('Only English Punctuation:', len(only_english_punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Traditional Simplified  \\\n",
      "0                %          %   \n",
      "1        2019冠狀病毒病  2019冠状病毒病   \n",
      "2          21三體綜合症    21三体综合症   \n",
      "3               3C         3C   \n",
      "4               3P         3P   \n",
      "...            ...        ...   \n",
      "121601           𨭆          𬭶   \n",
      "121602           𨭎          𬭳   \n",
      "121603           𩧢          𱅒   \n",
      "121604           𰻞          𰻝   \n",
      "121605         𰻞𰻞麵        𰻝𰻝面   \n",
      "\n",
      "                                                  Pinyin  \\\n",
      "0                                                    pa1   \n",
      "1       er4 ling2 yi1 jiu3 guan1 zhuang4 bing4 du2 bing4   \n",
      "2                 er4 shi2 yi1 san1 ti3 zong1 he2 zheng4   \n",
      "3                                                 san1 C   \n",
      "4                                                 san1 P   \n",
      "...                                                  ...   \n",
      "121601                                              hei1   \n",
      "121602                                               xi3   \n",
      "121603                                            cheng3   \n",
      "121604                                            biang2   \n",
      "121605                               biang2 biang2 mian4   \n",
      "\n",
      "                                                  English  \n",
      "0                                            percent (Tw)  \n",
      "1       COVID-19, the coronavirus disease identified i...  \n",
      "2                                 trisomy/Down's syndrome  \n",
      "3       abbr. for computers, communications, and consu...  \n",
      "4                                       (slang) threesome  \n",
      "...                                                   ...  \n",
      "121601                                hassium (chemistry)  \n",
      "121602                             seaborgium (chemistry)  \n",
      "121603                             variant of 騁|骋[cheng3]  \n",
      "121604                   see 𰻞𰻞麵|𰻝𰻝面[biang2 biang2 mian4]  \n",
      "121605     broad, belt-shaped noodles, popular in Shaanxi  \n",
      "\n",
      "[1068 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(non_chinese_trad)\n",
    "non_chinese_trad.to_csv('non_chinese_trad.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('cedict.json', orient='records', force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlite database\n",
    "conn = sqlite3.connect('cedict.db')\n",
    "c = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all tables\n",
    "c.execute('DROP TABLE IF EXISTS cedict;')\n",
    "c.execute('DROP TABLE IF EXISTS cedict_lookup;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE cedict (\n",
    "    ID INTEGER PRIMARY KEY AUTOINCREMENT, \n",
    "    Traditional TEXT, \n",
    "    Simplified TEXT, \n",
    "    Pinyin TEXT, \n",
    "    English TEXT)''')\n",
    "conn.commit()\n",
    "df.to_sql('cedict', conn, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE cedict_lookup (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT, \n",
    "    Lookup TEXT, \n",
    "    cedict_id INTEGER,\n",
    "    UNIQUE(Lookup, cedict_id),\n",
    "    FOREIGN KEY(cedict_id) REFERENCES cedict(ID))''')\n",
    "c.execute('CREATE INDEX lookup_index ON cedict_lookup(Lookup)')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO cedict_lookup (Lookup, cedict_id) VALUES (?, ?) ON CONFLICT (Lookup, cedict_id) DO NOTHING\n"
     ]
    }
   ],
   "source": [
    "cedict_query = 'INSERT INTO cedict_lookup (Lookup, cedict_id) VALUES (?, ?)'\n",
    "cedict_query += ' ON CONFLICT (Lookup, cedict_id) DO NOTHING'\n",
    "print(cedict_query)\n",
    "for row in c.execute('SELECT ID, Traditional, Simplified FROM cedict').fetchall():\n",
    "    c.execute(cedict_query, (row[1], row[0]))\n",
    "    c.execute(cedict_query, (row[2], row[0]))\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_query = pandas.read_sql_query(\n",
    "    'SELECT * FROM cedict WHERE Simplified = \"的\"', conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_windows_path_to_unix(path):\n",
    "    return path.replace('\\\\', '/')\n",
    "\n",
    "\n",
    "path = r\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "path = convert_windows_path_to_unix(path)\n",
    "print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(75089, '的', '的', 'de5', \"of; ~'s (possessive particle)/(used after an attribute)/(used to form a nominal expression)/(used at the end of a declarative sentence for emphasis)/also pr. [di4] or [di5] in poetry and songs\"), (75090, '的', '的', 'di1', 'see 的士[di1 shi4]'), (75091, '的', '的', 'di2', 'really and truly'), (75092, '的', '的', 'di4', \"(bound form) bull's-eye; target\")]\n",
      "[(150177, '的', 75089), (150179, '的', 75090), (150181, '的', 75091), (150183, '的', 75092)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def check_db(path):\n",
    "    conn = sqlite3.connect(path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT * FROM cedict WHERE Simplified = \"的\"')\n",
    "    print(c.fetchall())\n",
    "    c.execute('SELECT * FROM cedict_lookup WHERE Lookup = \"的\"')\n",
    "    print(c.fetchall())\n",
    "\n",
    "\n",
    "check_db('cedict.db')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
